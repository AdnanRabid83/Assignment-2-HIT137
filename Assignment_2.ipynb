{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "M3wKkqzoHtI6",
        "outputId": "2f8f35e5-4f05-4587-93d4-03aae6daa31e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_91996df3-28a4-40e7-8b2a-f9edd9776393\", \"combined_text.txt\", 708519196)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text extraction complete and saved to 'combined_text.txt'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "csv_folder = 'CSV'\n",
        "csv_files = ['CSV1.csv', 'CSV2.csv', 'CSV3.csv', 'CSV4.csv']\n",
        "all_text = ''\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    file_path = os.path.join(csv_folder, csv_file)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    if 'TEXT' in df.columns:\n",
        "        all_text += '\\n'.join(df['TEXT'].astype(str)) + '\\n'\n",
        "    elif 'SHORT-TEXT' in df.columns:\n",
        "        all_text += '\\n'.join(df['SHORT-TEXT'].astype(str)) + '\\n'\n",
        "    else:\n",
        "        print(f\"No 'TEXT' or 'SHORT-TEXT' column found in {csv_file}\")\n",
        "\n",
        "with open('combined_text.txt', 'w') as txt_file:\n",
        "    txt_file.write(all_text)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('combined_text.txt')\n",
        "\n",
        "print(\"Text extraction complete and saved to 'combined_text.txt'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avwoFq5QRGxM",
        "outputId": "b3f16614-585e-429e-cffb-046b68a992df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.4.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.18)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: scispacy in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Collecting spacy<3.8.0,>=3.7.0 (from scispacy)\n",
            "  Using cached spacy-3.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: scipy<1.11 in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (2.32.3)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.10/dist-packages (from scispacy) (5.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.26.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.4.2)\n",
            "Requirement already satisfied: nmslib>=1.7.3.6 in /usr/local/lib/python3.10/dist-packages (from scispacy) (2.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.3.2)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.10/dist-packages (from scispacy) (0.3.4)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.10/dist-packages (from nmslib>=1.7.3.6->scispacy) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nmslib>=1.7.3.6->scispacy) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->scispacy) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.9)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8.0,>=3.7.0->scispacy)\n",
            "  Using cached thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (4.66.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.10.18)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (4.12.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->scispacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.0)\n",
            "Using cached spacy-3.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.0 MB)\n",
            "Using cached thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-sci-sm 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.6 which is incompatible.\n",
            "en-ner-bc5cdr-md 0.5.1 requires spacy<3.5.0,>=3.4.1, but you have spacy 3.7.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.7.6 thinc-8.2.5\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz (15.9 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spacy<3.5.0,>=3.4.1 (from en_core_sci_sm==0.5.1)\n",
            "  Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (3.0.9)\n",
            "Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1)\n",
            "  Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2.0.10)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (1.10.18)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (1.2.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en_core_sci_sm==0.5.1) (1.2.0)\n",
            "Using cached spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "Using cached thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.5\n",
            "    Uninstalling thinc-8.2.5:\n",
            "      Successfully uninstalled thinc-8.2.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.6\n",
            "    Uninstalling spacy-3.7.6:\n",
            "      Successfully uninstalled spacy-3.7.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.4.4 which is incompatible.\n",
            "scispacy 0.5.4 requires spacy<3.8.0,>=3.7.0, but you have spacy 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.4.4 thinc-8.1.12\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz (120.2 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.5.0,>=3.4.1 in /usr/local/lib/python3.10/dist-packages (from en_ner_bc5cdr_md==0.5.1) (3.4.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2.0.10)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (1.10.18)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (3.4.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (1.2.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.1->en_ner_bc5cdr_md==0.5.1) (1.2.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SciSpaCy (en_core_sci_sm) Entities:\n",
            "patient ENTITY\n",
            "prescribed ENTITY\n",
            "acetaminophen ENTITY\n",
            "pain relief ENTITY\n",
            "potential ENTITY\n",
            "side effects ENTITY\n",
            "SciSpaCy (en_ner_bc5cdr_md) Entities:\n",
            "acetaminophen CHEMICAL\n",
            "pain DISEASE\n",
            "BioBERT Output:\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1877,  0.1467,  0.1031,  ..., -0.2658,  0.4110, -0.1254],\n",
            "         [-0.1456, -0.2974,  0.4535,  ...,  0.1741,  0.4343,  0.1967],\n",
            "         [-0.2145, -0.1803,  0.4841,  ...,  0.1533,  0.3381, -0.2829],\n",
            "         ...,\n",
            "         [ 0.4864,  0.3278,  0.4823,  ...,  0.4097, -0.0030, -0.1525],\n",
            "         [-0.1283,  0.0669,  0.2620,  ..., -0.2603,  0.0069, -0.1416],\n",
            "         [ 0.7869,  0.0212, -0.3806,  ..., -1.0841,  0.3382,  0.2066]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 2.9977e-03,  8.7000e-02,  9.8252e-01, -1.0000e+00,  1.0000e+00,\n",
            "          8.4160e-02, -3.4748e-02,  9.6271e-01, -1.1912e-01, -1.2555e-02,\n",
            "          9.5708e-01,  9.9998e-01,  5.7538e-01, -9.4568e-01,  4.2053e-02,\n",
            "          6.8098e-02,  1.0000e+00,  9.0778e-05, -9.9956e-01,  2.0674e-02,\n",
            "         -9.0308e-02, -9.8862e-01, -4.7384e-02,  9.8378e-01, -5.4912e-02,\n",
            "          1.3679e-01,  9.9998e-01,  9.9948e-01,  2.5121e-02, -5.1704e-03,\n",
            "         -7.2126e-02, -1.0000e+00,  9.9909e-01, -9.9999e-01, -1.4361e-02,\n",
            "         -2.2433e-02,  2.1326e-02, -4.7472e-02,  8.2040e-01, -9.9944e-01,\n",
            "         -8.3391e-02, -7.8484e-01, -1.5654e-01, -6.9419e-02,  9.9692e-01,\n",
            "         -1.2691e-01,  2.4774e-02, -5.2399e-03,  4.2635e-02,  3.8022e-01,\n",
            "          1.3307e-01,  9.9707e-01,  9.2683e-01,  9.9910e-01,  9.9996e-01,\n",
            "          1.4959e-01,  1.0000e+00,  7.9500e-02,  9.7841e-01,  6.8906e-02,\n",
            "          1.0000e+00, -2.7650e-02, -1.1651e-02, -1.1962e-01, -4.1405e-02,\n",
            "          3.0495e-03, -5.9388e-01, -2.6922e-02, -1.0891e-01,  7.9592e-02,\n",
            "          9.2705e-02, -8.7681e-03,  9.9957e-01, -9.9998e-01, -8.4829e-02,\n",
            "         -7.5760e-03,  3.9063e-02, -9.9028e-01,  9.9990e-01,  9.9997e-01,\n",
            "          1.9083e-01, -9.9965e-01,  1.0000e+00,  3.8287e-02, -4.6483e-02,\n",
            "          7.2107e-02,  9.6035e-01, -9.9999e-01,  7.7275e-02, -1.0580e-02,\n",
            "          4.3917e-01, -9.9999e-01, -5.5954e-03, -7.1102e-01,  9.9966e-01,\n",
            "          5.2978e-01, -1.1495e-01, -7.4401e-03, -7.5227e-02, -1.9030e-01,\n",
            "         -1.3078e-01,  9.7150e-01, -6.4924e-01,  8.6313e-01, -5.1751e-01,\n",
            "          9.5592e-02,  1.0442e-01, -1.0333e-01, -1.4553e-02, -1.4197e-02,\n",
            "          1.4874e-02,  8.0280e-02, -1.3474e-01, -1.6961e-02,  9.8878e-01,\n",
            "          8.7250e-01,  1.0000e+00,  9.7562e-01, -1.2529e-02,  9.9968e-01,\n",
            "         -6.3919e-02,  9.9173e-01,  9.9998e-01,  2.4896e-02, -7.4979e-02,\n",
            "         -2.4976e-02, -1.2100e-01,  9.9911e-01, -5.6192e-03,  7.4107e-02,\n",
            "          1.0075e-01, -9.9999e-01, -9.9848e-01,  9.9958e-01, -2.1762e-02,\n",
            "          9.9998e-01, -9.9997e-01,  8.2842e-01, -9.9115e-01, -1.0371e-01,\n",
            "         -8.3734e-01, -1.4883e-02, -9.7998e-01, -9.5464e-02,  9.9997e-01,\n",
            "         -2.9121e-02, -9.9810e-01, -2.5851e-01, -4.7834e-02, -1.8875e-01,\n",
            "         -2.2443e-02,  1.2127e-01,  3.7461e-02,  9.9813e-01,  6.4371e-01,\n",
            "          9.9897e-01,  9.9852e-01,  6.1797e-02,  5.1565e-02,  7.7369e-01,\n",
            "         -3.3514e-02, -9.9989e-01, -3.8433e-03, -9.9902e-01,  9.9705e-01,\n",
            "          9.9998e-01, -7.2524e-03,  9.7882e-01,  9.9994e-01, -1.4761e-02,\n",
            "          1.2046e-01,  1.1657e-01,  3.1961e-02,  9.2453e-01,  9.2841e-02,\n",
            "          5.9486e-02,  3.2328e-02,  1.2736e-02, -9.9997e-01,  7.5868e-03,\n",
            "          9.5871e-01, -7.1851e-02,  6.7889e-02, -9.8565e-01, -1.0000e+00,\n",
            "          5.4421e-02, -9.9978e-01,  1.1313e-01,  5.8140e-02,  8.6013e-02,\n",
            "         -8.9660e-02,  9.9993e-01, -9.3567e-01, -1.1908e-02, -2.1230e-02,\n",
            "          4.4585e-02,  9.9951e-01,  4.9931e-02,  9.9986e-01, -6.5060e-02,\n",
            "         -1.0000e+00, -9.7962e-01, -5.3530e-01,  7.5652e-02, -1.9369e-01,\n",
            "         -1.1451e-01,  4.1426e-02,  2.6485e-02, -9.3468e-01, -9.9820e-01,\n",
            "         -9.7171e-01,  1.3576e-02,  6.7615e-02, -1.2174e-01, -8.0458e-02,\n",
            "          3.1344e-01, -3.6507e-02,  5.7323e-02,  4.8807e-02,  9.9971e-01,\n",
            "         -9.9999e-01, -1.2054e-01,  2.8196e-02, -9.9999e-01, -1.0000e+00,\n",
            "         -2.9871e-02, -9.3581e-02, -9.0921e-01,  4.0457e-02, -7.4875e-01,\n",
            "          7.7131e-02,  9.0543e-01,  1.0000e+00, -3.3289e-02, -1.8444e-01,\n",
            "         -9.9950e-01,  9.1919e-01,  1.2009e-01,  2.3141e-03, -5.1140e-02,\n",
            "          2.3442e-02,  2.3082e-02, -4.3033e-02, -8.5833e-01, -4.4620e-02,\n",
            "          1.3795e-01, -6.7006e-01,  1.6375e-01,  4.6071e-02,  7.0028e-02,\n",
            "          1.3267e-01,  7.9702e-01,  1.3147e-01,  1.0000e+00, -9.9953e-01,\n",
            "          3.6400e-01,  9.9127e-01, -9.9998e-01,  9.5812e-02,  9.3716e-01,\n",
            "          6.2233e-02, -9.9728e-01, -4.8343e-02,  4.3450e-02, -2.0313e-01,\n",
            "          5.0907e-03,  1.0000e+00,  9.3876e-02, -6.7096e-02, -1.0186e-02,\n",
            "         -9.9889e-01,  3.5151e-02, -4.2881e-02,  1.0000e+00,  9.1772e-01,\n",
            "          2.6074e-03,  1.0356e-02, -7.0900e-02, -1.0000e+00, -9.7333e-01,\n",
            "         -7.2634e-02,  9.8475e-01, -1.0000e+00, -1.2015e-01,  9.9978e-01,\n",
            "          9.8400e-01,  1.2636e-01, -9.9988e-01, -6.9140e-02, -9.9998e-01,\n",
            "          2.1092e-02, -8.7784e-02,  4.1375e-02, -1.0379e-02, -2.4567e-02,\n",
            "         -6.9883e-02,  9.9990e-01,  9.9917e-01, -6.4725e-02,  2.6173e-02,\n",
            "          7.8385e-03, -1.0000e+00, -9.9699e-01, -1.4502e-01,  6.5966e-02,\n",
            "         -9.9862e-01,  1.0000e+00, -9.9867e-01,  9.9875e-01,  9.9781e-01,\n",
            "          9.6250e-01,  1.0483e-01, -2.4501e-02, -9.9818e-01, -3.4634e-02,\n",
            "          9.9914e-01,  9.9987e-01,  4.1915e-03,  1.4329e-02,  9.3596e-01,\n",
            "          6.9469e-02,  5.5501e-02, -4.4526e-02,  1.5902e-01,  5.4129e-02,\n",
            "         -8.7897e-02,  3.4707e-01, -6.6869e-01, -9.7135e-01,  3.5565e-01,\n",
            "          4.9294e-02, -1.0000e-01, -4.8527e-01, -6.0800e-02,  5.9133e-02,\n",
            "         -1.1067e-01, -1.6355e-01, -6.5335e-02, -3.4592e-01,  1.6576e-01,\n",
            "          5.7685e-02,  7.8300e-01,  1.4746e-01,  7.1650e-01,  4.6142e-02,\n",
            "         -9.9853e-01,  9.9966e-01, -2.1130e-02, -6.9211e-01,  9.7297e-01,\n",
            "          9.9942e-01, -9.9984e-01,  3.0770e-02, -6.0748e-02, -3.3879e-02,\n",
            "         -4.8154e-02,  1.0000e+00, -8.2075e-01, -1.6053e-01,  3.6716e-01,\n",
            "         -5.7718e-02, -4.5571e-02,  5.5682e-02,  1.6002e-01, -3.5678e-04,\n",
            "          9.4475e-01, -4.9774e-02,  9.9831e-01, -9.1523e-01, -6.4296e-02,\n",
            "          6.1793e-02, -4.2001e-01,  3.7821e-02,  1.2524e-02, -5.2463e-01,\n",
            "          6.2112e-03, -8.5689e-01,  5.3730e-02, -8.9721e-01,  3.1856e-03,\n",
            "          9.9916e-01, -3.6651e-02, -3.3641e-02,  2.2241e-01,  7.0921e-02,\n",
            "          9.9999e-01, -1.0000e+00, -7.4095e-02,  9.9998e-01, -1.1868e-01,\n",
            "          3.9369e-04,  1.1785e-01, -9.6349e-01,  1.2124e-02, -7.2001e-02,\n",
            "         -9.9907e-01,  3.3149e-02, -1.2114e-01,  5.2262e-02,  1.2660e-03,\n",
            "          1.1138e-01, -8.6860e-02,  6.4531e-01,  1.0487e-02, -4.7850e-03,\n",
            "          1.0850e-01, -6.0353e-02, -2.9868e-02, -6.3995e-02, -6.7673e-03,\n",
            "         -1.5128e-02, -4.5919e-02, -1.0039e-01, -3.4110e-02,  1.0756e-01,\n",
            "          9.9408e-01,  1.1369e-01, -9.9971e-01,  9.6682e-01,  5.7722e-02,\n",
            "         -9.9386e-01,  3.5915e-02, -9.9972e-01,  1.0000e+00,  9.9907e-01,\n",
            "          9.6169e-01,  9.1592e-01, -9.9984e-01, -9.9925e-01, -2.3507e-01,\n",
            "         -2.3036e-02,  5.1245e-03,  4.0030e-03,  9.6788e-01,  5.2886e-02,\n",
            "          2.1404e-02,  4.0596e-02,  1.5143e-01, -1.1980e-02,  9.6435e-01,\n",
            "         -2.3267e-01, -9.9986e-01, -1.1920e-01,  8.1812e-01,  9.3252e-01,\n",
            "         -7.3200e-01,  1.2325e-02, -9.3792e-01, -1.0786e-01,  1.1171e-01,\n",
            "          1.3438e-02, -4.0908e-02,  5.8900e-02, -9.5316e-01, -2.1066e-02,\n",
            "         -3.3145e-02, -2.3728e-02, -1.1816e-01,  7.2623e-03,  9.5953e-01,\n",
            "         -9.3766e-01, -8.6826e-02, -1.1845e-02, -4.8272e-01, -6.9731e-01,\n",
            "         -9.3280e-01, -4.3378e-01, -9.4366e-01,  3.0431e-02,  7.5040e-03,\n",
            "         -9.9940e-01,  2.2943e-02,  9.7423e-01,  9.9842e-01,  9.9987e-01,\n",
            "          4.5146e-04,  6.2741e-02, -2.5698e-02,  7.5277e-02, -9.9958e-01,\n",
            "          1.2904e-01,  1.7883e-01,  1.3746e-01, -3.5819e-01,  5.3283e-02,\n",
            "         -3.5557e-03,  9.5965e-01, -9.9947e-01,  9.9697e-01,  3.4178e-02,\n",
            "         -1.7807e-02, -1.4845e-01, -3.0838e-04,  4.1388e-02,  1.1512e-01,\n",
            "         -9.9994e-01,  1.5169e-01,  1.0000e+00,  9.8664e-01,  9.9564e-01,\n",
            "          8.7602e-01, -9.4671e-01,  8.4362e-02, -8.6279e-02, -9.9818e-01,\n",
            "         -9.9806e-01,  9.9762e-02, -1.6204e-01, -9.9984e-01,  9.9119e-01,\n",
            "         -9.9902e-01,  8.3313e-02, -1.4137e-01,  9.9913e-01,  9.9993e-01,\n",
            "          2.9791e-02, -9.9979e-01, -9.9991e-01,  9.5808e-01,  4.3725e-04,\n",
            "          1.3696e-02,  2.6229e-02, -4.9594e-02,  3.5647e-02, -1.4828e-02,\n",
            "          9.8802e-01, -1.9968e-02, -4.1545e-02,  6.7928e-01,  9.9999e-01,\n",
            "          7.6337e-02, -9.9876e-01, -3.3653e-01,  5.8579e-02, -8.3785e-01,\n",
            "          5.2204e-02,  9.9935e-01, -3.0401e-02,  9.5805e-01,  9.9946e-01,\n",
            "         -9.9962e-01,  9.8797e-01, -9.9987e-01,  9.5781e-01,  9.9964e-01,\n",
            "         -1.0000e+00, -7.1499e-02, -1.0000e+00, -6.8924e-01,  4.3497e-02,\n",
            "          8.1054e-02, -8.2937e-03,  9.0491e-01, -1.0000e+00, -9.9995e-01,\n",
            "         -3.0451e-02, -6.6926e-02, -9.2927e-01,  7.3124e-01,  7.8320e-02,\n",
            "          1.7791e-01,  6.3225e-02, -6.2840e-02,  2.0614e-02, -8.2262e-01,\n",
            "          9.9979e-01, -7.9416e-02,  8.4574e-02, -1.0000e+00,  9.9910e-01,\n",
            "         -1.4004e-02, -3.5847e-02,  1.0000e+00, -7.1483e-02,  3.1460e-02,\n",
            "          1.7254e-02, -1.0000e+00, -1.2320e-01,  1.1248e-01, -9.9225e-01,\n",
            "          7.8395e-01,  6.9345e-02, -5.6174e-02,  8.4699e-02, -4.6964e-02,\n",
            "         -9.9606e-01,  1.0545e-01, -1.0000e+00,  1.0000e+00, -9.5109e-01,\n",
            "          3.5956e-02,  2.2527e-03, -7.0820e-03,  2.7824e-02,  9.9359e-01,\n",
            "          1.0000e+00, -9.9974e-01, -8.9559e-02,  1.0000e+00, -1.9312e-02,\n",
            "         -1.7537e-02, -1.0000e+00,  1.9638e-02, -9.3697e-01, -2.5845e-02,\n",
            "          1.0000e+00, -5.2620e-02, -8.0567e-02,  9.9985e-01, -1.0000e+00,\n",
            "         -6.2992e-01,  7.9798e-02, -1.1025e-01, -1.1458e-02, -1.0000e+00,\n",
            "         -3.7500e-03, -9.7499e-01,  6.1857e-02, -1.0000e+00,  9.9756e-01,\n",
            "         -1.0000e+00, -8.4094e-02,  9.9999e-01, -9.2154e-01,  9.9961e-01,\n",
            "          2.4272e-02, -3.8108e-02,  1.1013e-02, -9.9999e-01,  7.7431e-01,\n",
            "          6.6250e-02,  1.5505e-02, -9.9794e-01, -9.6578e-01, -8.8708e-02,\n",
            "          7.1605e-01, -9.7718e-01,  2.6727e-02, -6.2909e-01, -5.9085e-02,\n",
            "          7.3901e-02,  3.0875e-02,  1.6936e-01, -4.9619e-01,  1.4010e-01,\n",
            "          1.7003e-02,  1.2633e-01,  7.0124e-02,  5.5691e-02, -7.0377e-02,\n",
            "          9.9586e-01, -1.0000e+00,  2.7846e-02, -9.9993e-01, -3.9388e-02,\n",
            "         -3.9926e-03,  6.9097e-02, -2.8485e-02, -2.7320e-02, -1.1452e-03,\n",
            "         -9.9903e-01,  1.0000e+00, -1.0000e+00, -1.0000e+00,  9.9999e-01,\n",
            "          1.6971e-01, -9.8487e-01, -8.7806e-02,  1.8404e-02,  9.5343e-02,\n",
            "          1.0574e-01,  1.8655e-01,  4.1577e-02, -1.7976e-02, -9.9297e-01,\n",
            "          9.7686e-01, -3.6400e-02, -7.2978e-02,  5.6683e-02, -1.4845e-01,\n",
            "         -9.9519e-01,  1.0000e+00,  1.0000e+00,  9.9947e-01, -9.9995e-01,\n",
            "         -1.7916e-02,  5.2378e-02,  1.0000e+00, -1.1204e-01, -8.2554e-02,\n",
            "          9.9495e-01,  9.9525e-01,  7.3486e-02, -9.0473e-01,  8.5671e-02,\n",
            "          8.9727e-03,  1.0425e-03, -7.5156e-02, -9.8810e-01, -9.9961e-01,\n",
            "          2.9439e-02, -9.9981e-01, -9.9443e-01,  9.8334e-01, -1.0873e-01,\n",
            "          1.0000e+00,  2.3445e-02,  1.3712e-01,  1.6700e-01, -8.6532e-01,\n",
            "         -9.9924e-01,  8.8253e-02, -9.9852e-01,  2.7254e-02, -9.9998e-01,\n",
            "         -1.0000e+00,  8.9274e-02, -6.1335e-02, -9.9734e-01,  5.5563e-03,\n",
            "         -1.4963e-02, -9.9898e-01, -9.1307e-01, -9.9951e-01,  7.5205e-01,\n",
            "         -9.1728e-01, -9.8796e-01,  1.1834e-01,  2.4679e-01, -7.8054e-02,\n",
            "          1.4801e-02, -7.5955e-01,  9.7142e-01,  7.0484e-01,  6.2775e-02,\n",
            "          8.0510e-02,  1.5135e-01, -9.9878e-01, -7.0497e-02, -1.0000e+00,\n",
            "          9.9741e-01, -1.0000e+00,  1.0560e-01,  1.0000e+00,  1.0000e+00,\n",
            "          3.8617e-02, -9.9999e-01,  9.9963e-01, -7.0558e-02,  1.0000e+00,\n",
            "          7.5746e-03, -9.9927e-01, -9.9999e-01,  7.5160e-02,  6.3790e-02,\n",
            "          1.0000e+00,  8.9102e-02,  9.7684e-01, -7.6066e-03,  5.9574e-03,\n",
            "         -3.6412e-02, -9.5532e-03,  4.1979e-02, -2.4899e-02,  3.0381e-02,\n",
            "          9.9727e-01, -1.4271e-01,  1.0000e+00]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install spacy\n",
        "!pip install scispacy\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
        "\n",
        "import spacy\n",
        "import scispacy\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "nlp_sci_sm = spacy.load(\"en_core_sci_sm\")\n",
        "nlp_bc5cdr = spacy.load(\"en_ner_bc5cdr_md\")\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "text = \"The patient was prescribed acetaminophen for pain relief and is being monitored for potential side effects.\"\n",
        "doc_sci_sm = nlp_sci_sm(text)\n",
        "print(\"SciSpaCy (en_core_sci_sm) Entities:\")\n",
        "for ent in doc_sci_sm.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "doc_bc5cdr = nlp_bc5cdr(text)\n",
        "print(\"SciSpaCy (en_ner_bc5cdr_md) Entities:\")\n",
        "for ent in doc_bc5cdr.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"BioBERT Output:\")\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajL4ERGhKQql",
        "outputId": "e57510a3-362a-485a-b530-e40351b26de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Word    Count\n",
            "1       and  2341409\n",
            "2       the  2158529\n",
            "3        to  1931537\n",
            "4        of  1926215\n",
            "5       was  1867807\n",
            "6      with  1366827\n",
            "7         a  1151764\n",
            "8        on  1104052\n",
            "9        in  1000773\n",
            "10      for   976439\n",
            "11       is   775103\n",
            "12       mg   725803\n",
            "13       no   552340\n",
            "14  patient   525955\n",
            "15      The   497153\n",
            "16       at   496295\n",
            "17       or   479400\n",
            "18   Tablet   452050\n",
            "19       as   450188\n",
            "20       PO   408981\n",
            "21      (1)   381504\n",
            "22     Sig:   371957\n",
            "23      **]   371169\n",
            "24     Name   364713\n",
            "25     were   347112\n",
            "26       he   346640\n",
            "27      his   346495\n",
            "28      her   329535\n",
            "29     left   326477\n",
            "30      had   321160\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import pandas as pd\n",
        "\n",
        "with open('combined_text.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "words = text.split()\n",
        "word_counts = collections.Counter(words)\n",
        "top_30_words = word_counts.most_common(30)\n",
        "df = pd.DataFrame(top_30_words, columns=['Word', 'Count'])\n",
        "df.index = df.index + 1\n",
        "df.to_csv('top_30_words.csv', index_label='Index')\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBXsgUMALc9s",
        "outputId": "54c846c5-fe33-49f7-c328-ed407fa9ccd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CSV1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (16988983 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 30 words in CSV1:\n",
            "{'the': 536852, 'and': 486257, 'was': 404847, 'to': 398959, 'of': 396562, 'with': 281895, 'on': 261595, 'in': 260868, '##t': 219587, 'a': 205420, 'is': 192338, 'for': 185079, 'blood': 175151, 'he': 163488, '##s': 160599, '##c': 153052, 'no': 138535, 'mg': 136428, 'she': 131349, 'am': 127483, 'at': 123335, 'h': 119434, 'patient': 118721, 'as': 117425, 'pt': 106282, 'pm': 102333, 'mc': 99657, '##g': 95963, 'her': 93208, 'name': 90414}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def count_unique_tokens_and_top_words(csv_file_path, chunk_size=10000):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    token_counts = Counter()\n",
        "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):\n",
        "        if 'TEXT' in chunk.columns:\n",
        "            text_column = 'TEXT'\n",
        "        elif 'SHORT-TEXT' in chunk.columns:\n",
        "            text_column = 'SHORT-TEXT'\n",
        "        else:\n",
        "            raise ValueError(\"No recognizable text column found in the CSV file.\")\n",
        "        text = ' '.join(chunk[text_column].astype(str))\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_counts.update(tokens)\n",
        "    top_30_words = dict(token_counts.most_common(30))\n",
        "\n",
        "    return top_30_words\n",
        "csv_files = {\n",
        "    'CSV1': 'CSV/CSV1.csv'\n",
        "}\n",
        "for name, path in csv_files.items():\n",
        "    print(f\"Processing {name}\")\n",
        "    top_words = count_unique_tokens_and_top_words(path)\n",
        "    print(f\"Top 30 words in {name}:\")\n",
        "    print(top_words)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo7MQYMxYKF_",
        "outputId": "2037ed3c-3e0b-4b95-f417-240305bb2059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CSV2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5442360 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 30 words in CSV2:\n",
            "{'*': 370489, '.': 281993, '-': 193374, ':': 121821, ',': 113596, '[': 83750, ']': 83748, ')': 71836, '(': 70064, 'the': 62176, 'and': 55238, 'to': 49961, 'of': 47560, 'was': 44325, '1': 42387, 'with': 34645, '/': 34542, '2': 33485, 'in': 33170, 'a': 32311, 'on': 30744, 'name': 25354, 'for': 24452, '3': 23083, 'mg': 22658, '##s': 22473, '##g': 22360, '5': 21235, 'no': 21208, 'tablet': 20590}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def count_unique_tokens_and_top_words(csv_file_path, chunk_size=10000):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    token_counts = Counter()\n",
        "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):\n",
        "        if 'TEXT' in chunk.columns:\n",
        "            text_column = 'TEXT'\n",
        "        elif 'SHORT-TEXT' in chunk.columns:\n",
        "            text_column = 'SHORT-TEXT'\n",
        "        else:\n",
        "            raise ValueError(\"No recognizable text column found in the CSV file.\")\n",
        "        text = ' '.join(chunk[text_column].astype(str))\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_counts.update(tokens)\n",
        "    top_30_words = dict(token_counts.most_common(30))\n",
        "\n",
        "    return top_30_words\n",
        "csv_files = {\n",
        "    'CSV2': 'CSV/CSV2.csv'\n",
        "}\n",
        "for name, path in csv_files.items():\n",
        "    print(f\"Processing {name}\")\n",
        "    top_words = count_unique_tokens_and_top_words(path)\n",
        "    print(f\"Top 30 words in {name}:\")\n",
        "    print(top_words)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqanWP0NY8Sw",
        "outputId": "f54b8a87-a98a-4cbe-c939-794868738205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CSV3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def count_unique_tokens_and_top_words(csv_file_path, chunk_size=10000):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    token_counts = Counter()\n",
        "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):\n",
        "        if 'TEXT' in chunk.columns:\n",
        "            text_column = 'TEXT'\n",
        "        elif 'SHORT-TEXT' in chunk.columns:\n",
        "            text_column = 'SHORT-TEXT'\n",
        "        else:\n",
        "            raise ValueError(\"No recognizable text column found in the CSV file.\")\n",
        "        text = ' '.join(chunk[text_column].astype(str))\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_counts.update(tokens)\n",
        "    top_30_words = dict(token_counts.most_common(30))\n",
        "\n",
        "    return top_30_words\n",
        "csv_files = {\n",
        "    'CSV3': 'CSV/CSV3.csv'\n",
        "}\n",
        "for name, path in csv_files.items():\n",
        "    print(f\"Processing {name}\")\n",
        "    top_words = count_unique_tokens_and_top_words(path)\n",
        "    print(f\"Top 30 words in {name}:\")\n",
        "    print(top_words)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ3eGrLWdVQT",
        "outputId": "ef208034-1421-4e25-8998-906aac4f0c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing CSV4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (407531 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 30 words in CSV4:\n",
            "{'*': 29181, '.': 19961, '-': 16379, ':': 9252, ',': 8231, '[': 6477, ']': 6477, ')': 5355, '(': 5245, 'the': 4268, 'and': 4095, 'to': 3483, 'of': 3368, '1': 3045, 'was': 3009, '/': 2716, '2': 2581, 'with': 2390, 'in': 2367, 'a': 2207, '3': 2106, 'on': 2063, 'name': 1848, '5': 1839, 'for': 1838, '4': 1738, 'no': 1689, '##s': 1659, '##g': 1643, '##t': 1524}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from collections import Counter\n",
        "\n",
        "def count_unique_tokens_and_top_words(csv_file_path, chunk_size=10000):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    token_counts = Counter()\n",
        "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):\n",
        "        if 'TEXT' in chunk.columns:\n",
        "            text_column = 'TEXT'\n",
        "        elif 'SHORT-TEXT' in chunk.columns:\n",
        "            text_column = 'SHORT-TEXT'\n",
        "        else:\n",
        "            raise ValueError(\"No recognizable text column found in the CSV file.\")\n",
        "        text = ' '.join(chunk[text_column].astype(str))\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_counts.update(tokens)\n",
        "    top_30_words = dict(token_counts.most_common(30))\n",
        "\n",
        "    return top_30_words\n",
        "csv_files = {\n",
        "    'CSV4': 'CSV/CSV4.csv'\n",
        "}\n",
        "for name, path in csv_files.items():\n",
        "    print(f\"Processing {name}\")\n",
        "    top_words = count_unique_tokens_and_top_words(path)\n",
        "    print(f\"Top 30 words in {name}:\")\n",
        "    print(top_words)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DVt6FRIdlHZ",
        "outputId": "a6c7d781-dd52-4f02-e72d-4082b28af5f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "331052029\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "current_time = int(time.time())\n",
        "generated_number = (current_time % 100) + 50\n",
        "if generated_number % 2 == 0:\n",
        "    generated_number += 10\n",
        "input_image_path = 'Image/chapter1.jpg'\n",
        "output_image_path = 'Image/chapter1out.png'\n",
        "image = Image.open(input_image_path)\n",
        "pixels = image.load()\n",
        "width, height = image.size\n",
        "for y in range(height):\n",
        "    for x in range(width):\n",
        "        r, g, b = pixels[x, y]\n",
        "        new_r = min(r + generated_number, 255)\n",
        "        new_g = min(g + generated_number, 255)\n",
        "        new_b = min(b + generated_number, 255)\n",
        "        pixels[x, y] = (new_r, new_g, new_b)\n",
        "image.save(output_image_path)\n",
        "new_image = Image.open(output_image_path)\n",
        "new_pixels = new_image.load()\n",
        "\n",
        "red_sum = 0\n",
        "for y in range(height):\n",
        "    for x in range(width):\n",
        "        r, g, b = new_pixels[x, y]\n",
        "        red_sum += r\n",
        "print(red_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFqEqWML8KST",
        "outputId": "abd984b0-3884-4f69-89d5-6204926cfb00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number string: 5619842352781457853100\n",
            "Letter string: AsktraYmnsssq\n",
            "ASCII values of even numbers: [54, 56, 52, 50, 50, 56, 52, 56, 48, 48]\n",
            "ASCII values of uppercase letters: [65, 89]\n",
            "No valid shift key found.\n"
          ]
        }
      ],
      "source": [
        "def process_string(s):\n",
        "    number_str = ''.join(c for c in s if c.isdigit())\n",
        "    letter_str = ''.join(c for c in s if c.isalpha())\n",
        "    even_numbers = [int(c) for c in number_str if int(c) % 2 == 0]\n",
        "    upper_case_letters = [c for c in letter_str if c.isupper()]\n",
        "    ascii_even_numbers = [ord(c) for c in number_str if c.isdigit() and int(c) % 2 == 0]\n",
        "    ascii_upper_case_letters = [ord(c) for c in upper_case_letters]\n",
        "    return number_str, letter_str, ascii_even_numbers, ascii_upper_case_letters\n",
        "\n",
        "input_str = \"56A1984sktr235278aYmn145ss785/sq3100\"\n",
        "number_str, letter_str, ascii_even_numbers, ascii_upper_case_letters = process_string(input_str)\n",
        "\n",
        "print(f\"Number string: {number_str}\")\n",
        "print(f\"Letter string: {letter_str}\")\n",
        "print(f\"ASCII values of even numbers: {ascii_even_numbers}\")\n",
        "print(f\"ASCII values of uppercase letters: {ascii_upper_case_letters}\")\n",
        "\n",
        "\n",
        "def decrypt_cryptogram(ciphertext, s):\n",
        "    decrypted_text = []\n",
        "    for char in ciphertext:\n",
        "        if char.isalpha():\n",
        "            start = ord('A') if char.isupper() else ord('a')\n",
        "            decrypted_char = chr(start + (ord(char) - start - s) % 26)\n",
        "            decrypted_text.append(decrypted_char)\n",
        "        else:\n",
        "            decrypted_text.append(char)\n",
        "    return ''.join(decrypted_text)\n",
        "\n",
        "def find_shift_key(ciphertext, possible_plaintexts):\n",
        "    for s in range(1, 26):\n",
        "        decrypted_text = decrypt_cryptogram(ciphertext, s)\n",
        "        if decrypted_text in possible_plaintexts:\n",
        "            return s, decrypted_text\n",
        "    return None, None\n",
        "\n",
        "ciphertext = \"VZ FRYSVFU VZONGVRAG NAQ N YVGGYR VAFRPHER V ZNXR ZVFGNXRF V MZ BHG BS PBAGEBY NAONG GIZRE UNE GEB NAQUR ONG VS LBH PRAG UNAQYR ZR NG Z1 JBEFG GURA LBH FHER NE URYYQBAG ORFREIR ZR NG ZL ORFG ZHEVYLA ZBAE BR\"\n",
        "possible_plaintexts = [\"A famous quote\", \"Another possible plaintext\"]\n",
        "shift_key, decrypted_text = find_shift_key(ciphertext, possible_plaintexts)\n",
        "\n",
        "if shift_key:\n",
        "    print(f\"Shift key: {shift_key}\")\n",
        "    print(f\"Decrypted text: {decrypted_text}\")\n",
        "else:\n",
        "    print(\"No valid shift key found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcaEVLjYCNuY"
      },
      "outputs": [],
      "source": [
        "def encrypt(text, key):\n",
        "    encrypted_text = \"\"\n",
        " \n",
        "    for char in text:\n",
        "        if char.isalpha():\n",
        "            shifted = ord(char) + key\n",
        " \n",
        "            if char.islower():\n",
        "                if shifted > ord('z'):\n",
        "                    shifted -= 26\n",
        "                elif shifted < ord('a'):\n",
        "                    shifted += 26\n",
        "            elif char.isupper():\n",
        "                if shifted > ord('Z'):\n",
        "                    shifted -= 26\n",
        "                elif shifted < ord('A'):\n",
        "                    shifted += 26\n",
        " \n",
        "            encrypted_text += chr(shifted)\n",
        "        else:\n",
        "            encrypted_text += char\n",
        " \n",
        "    return encrypted_text\n",
        " \n",
        "key = 13\n",
        " \n",
        "original_code = \"\"\"\n",
        "def decrypt(text, key): \n",
        "    decrypted_text = \"\"\n",
        " \n",
        "    for char in text: \n",
        "        if char.isalpha():\n",
        "            shifted = ord(char) - key\n",
        " \n",
        "            if char.islower(): \n",
        "                if shifted < ord('a'): \n",
        "                    shifted += 26\n",
        "                elif shifted > ord('z'): \n",
        "                    shifted -= 26\n",
        "            elif char.isupper():\n",
        "                if shifted < ord('A'):\n",
        "                    shifted += 26\n",
        "                elif shifted > ord('Z'):\n",
        "                    shifted -= 26\n",
        " \n",
        "            decrypted_text += chr(shifted)\n",
        "        else:\n",
        "            decrypted_text += char\n",
        " \n",
        "    return decrypted_text\n",
        "\"\"\"\n",
        " \n",
        "encrypted_code = encrypt(original_code, key)  \n",
        "print(encrypted_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decrypt(text, key):\n",
        "    decrypted_text = ''\n",
        "    for char in text:\n",
        "        if char.isalpha():\n",
        "            shifted = ord(char) - key\n",
        "            if char.islower():\n",
        "                if shifted < ord('a'):\n",
        "                    shifted += 26\n",
        "            elif char.isupper():\n",
        "                if shifted < ord('A'):\n",
        "                    shifted += 26\n",
        "            decrypted_text += chr(shifted)\n",
        "        else:\n",
        "            decrypted_text += char\n",
        "    return decrypted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_variable = 100\n",
        " \n",
        "key_value_pairs = {'xrli': 'value1', 'xr12': 'value2', 'xr13': 'value3', 'xr14': 'value4'}\n",
        " \n",
        "def process_values():\n",
        "    global number_variable\n",
        "    number_variable = 5\n",
        "    values_list = [1, 2, 3, 4, 5]\n",
        " \n",
        "    for number in values_list:\n",
        "        if number > 0:\n",
        "            if number % 2 == 0:\n",
        "                values_list.remove(number)\n",
        " \n",
        "    return values_list\n",
        " \n",
        "original_list = (1, 2, 3, 4, 5, 5, 4, 3, 2, 1)\n",
        "result = process_values()\n",
        " \n",
        "def process_variable():\n",
        "    global number_variable\n",
        "    number_variable = 10\n",
        "    variable_value = key_value_pairs['xr14']\n",
        " \n",
        "process_variable()\n",
        " \n",
        "def demo_function():\n",
        "    global number_variable\n",
        "    number_variable += 10\n",
        " \n",
        "for v in range(5):\n",
        "    print(v)\n",
        " \n",
        "if 1 < 2:\n",
        "    print(\"Condition met\")\n",
        " \n",
        "if 'xr14' not in key_value_pairs:\n",
        "    print(\"Key 'xr14' is not in the dictionary\")\n",
        " \n",
        "if 5 not in key_value_pairs.values():\n",
        "    print(\"Value not found in key_value_pairs\")\n",
        " \n",
        "print(number_variable)\n",
        "print(key_value_pairs)\n",
        "print(original_list)\n",
        "has context menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decrypt(text, key):\n",
        "    decrypted_text = \"\"\n",
        "    for char in text:\n",
        "        if char.isalpha():\n",
        "            shifted = ord(char) - key\n",
        "            if char.islower():\n",
        "                if shifted < ord('a'):\n",
        "                    shifted += 26\n",
        "            elif char.isupper():\n",
        "                if shifted < ord('A'):\n",
        "                    shifted += 26\n",
        "            decrypted_text += chr(shifted)\n",
        "        else:\n",
        "            decrypted_text += char\n",
        "    return decrypted_text\n",
        "\n",
        "def ceaser_cipher_errors():\n",
        "    number = 100\n",
        "    encrypted_code = \"xrli': 'inyhr1', 'xr12': 'inyhrz', 'xr13': 'inyhr3'\"\n",
        "    \n",
        "    values = [1, 2, 3, 4, 5]\n",
        "    \n",
        "    def process_errors():\n",
        "        nonlocal values\n",
        "        number_variable = 5\n",
        "        for value in values[:]:\n",
        "            if value > 0:\n",
        "                if value % 2 == 0:\n",
        "                    values.remove(value)\n",
        "    \n",
        "    print(\"Initial values:\", values)\n",
        "    process_errors()\n",
        "    \n",
        "    key = 10\n",
        "    decrypted_code = decrypt(encrypted_code, key)\n",
        "    print(\"Decrypted code:\", decrypted_code)\n",
        "    \n",
        "    def process_numbers():\n",
        "        total = 0\n",
        "        for i in range(5):\n",
        "            for j in range(3):\n",
        "                if i + j == 5:\n",
        "                    total += i + j\n",
        "                else:\n",
        "                    total -= i - j\n",
        "\n",
        "        counter = 0\n",
        "        while counter < 5:\n",
        "            if total < 13:\n",
        "                total += 1\n",
        "            elif total > 13:\n",
        "                total -= 1\n",
        "            else:\n",
        "                counter += 2\n",
        "    \n",
        "    process_numbers()\n",
        "    \n",
        "ceaser_cipher_errors()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
